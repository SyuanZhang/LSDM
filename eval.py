# eval.py
import os
import argparse
import time
import torch
from torch.utils.data import DataLoader

# ä½ å·¥ç¨‹é‡Œçš„æ¨¡å—
from params import all_params
from wifi_model import tfdiff_WiFi
from diffusion import SignalDiffusion, GaussianDiffusion
from dataset import from_path  # ç”¨äºè§¦å‘æ•°æ®æ¨¡å—ï¼ˆä¹Ÿä¾¿äº fallbackï¼‰
try:
    # å¾ˆå¯èƒ½å­˜åœ¨è¿™ä¸ªç±»ï¼ˆæ ¹æ®ä½ æ—¥å¿—é‡Œ â€œInitializing TrafficDataset ...â€ï¼‰
    from dataset import TrafficDataset
except Exception:
    TrafficDataset = None

# è¯„ä¼°å·¥å…·ï¼ˆä½  util.py å·²ç»æœ‰ï¼‰
from util import (
    seed_everything, setup_tf32, get_device, dataloader_kwargs,
    evaluate_forecast, summarize_eval
)

def build_params(task_id: int, device_str: str):
    """å’Œä½ çš„ train.py ä¸€è‡´ï¼štask_id=4 æ—¶æ‰‹å·¥æ‹¼ä¸€ä»½é»˜è®¤å‚æ•°ã€‚"""
    if task_id == 4:
        from params import AttrDict
        import numpy as np
        return AttrDict(
            task_id=4,
            log_dir='./log/traffic_eval',
            model_dir='./model/traffic',
            data_dir=['./dataset/traffic'],
            traffic_path='traffic_data_new.npz',
            embedding_path='environment_embeddings.npz',
            max_iter=10000,
            batch_size=64,
            learning_rate=1e-4,
            max_grad_norm=0.5,
            inference_batch_size=64,
            robust_sampling=True,
            seq_len=24,
            pred_len=20,
            sample_rate=20,
            input_dim=20,
            output_dim=20,
            extra_dim=[128],
            cond_dim=148,
            embed_dim=128,
            hidden_dim=128,
            num_heads=4,
            num_block=8,
            dropout=0.1,
            mlp_ratio=4.0,
            learn_tfdiff=False,
            max_step=1000,
            signal_diffusion=True,
            blur_schedule=((1e-5**2) * np.ones(1000)).tolist(),
            noise_schedule=np.linspace(1e-4, 0.02, 1000).tolist(),
            device=device_str
        )
    return all_params[task_id]

def build_loader(params, split: str, batch_size: int, num_workers: int):
    if TrafficDataset is not None:
        # --- åªæ„é€  traffic_path ---
        def _abs_path(p):
            if os.path.isabs(p):
                return p
            root = params.data_dir[0] if isinstance(params.data_dir, (list, tuple)) else params.data_dir
            return os.path.abspath(os.path.join(root, p))

        traffic_path = _abs_path(params.traffic_path)
        
        if not os.path.exists(traffic_path):
            raise FileNotFoundError(f"Traffic data file not found: {traffic_path}")

        # --- åªä¼ é€’å¿…éœ€å‚æ•° ---
        dataset = TrafficDataset(
            mode=split,
            traffic_path=traffic_path,
            # ä¸ä¼  embedding_path
        )

        loader = DataLoader(
            dataset,
            **dataloader_kwargs(
                batch_size=batch_size,
                num_workers=num_workers,
                pin_memory=True,
                persistent_workers=False,
            )
        )
        return loader

    print("[WARN] dataset.TrafficDataset ä¸å¯ç”¨ï¼Œé€€åŒ–ä¸º from_path(params) çš„é»˜è®¤ DataLoader")
    loader = from_path(params)
    return loader


def load_model_and_diffusion(params, device):
    model = tfdiff_WiFi(params).to(device)
    diffusion = (SignalDiffusion(params) if params.signal_diffusion else GaussianDiffusion(params)).to(device)
    return model, diffusion

def load_checkpoint_into_model(model, ckpt_path: str, map_location):
    if not os.path.exists(ckpt_path):
        # å°è¯• {model_dir}/weights.pt
        alt = os.path.join(os.path.abspath(os.path.dirname(ckpt_path)), 'weights.pt')
        raise FileNotFoundError(f"Checkpoint ä¸å­˜åœ¨: {ckpt_path}")
    state = torch.load(ckpt_path, map_location=map_location)
    if 'model' in state:
        state = state['model']
    model.load_state_dict(state, strict=True)

def run_eval(args):
    seed_everything(42, deterministic=False)
    setup_tf32(True)

    device = get_device(args.device)
    params = build_params(args.task_id, device.type)

    # DataLoader
    loader = build_loader(
        params,
        split=args.split,
        batch_size=args.batch_size or params.inference_batch_size,
        num_workers=args.num_workers
    )

    # Model & diffusion
    model, diffusion = load_model_and_diffusion(params, device)
    model.eval()

    # Checkpoint
    ckpt = args.ckpt or os.path.join(params.model_dir, 'weights.pt')
    print(f"ğŸ” Loading checkpoint: {ckpt}")
    load_checkpoint_into_model(model, ckpt, map_location=device)
    print("âœ… Checkpoint loaded.")

    # æ¨ç†å¹¶ç´¯ç§¯æ‰€æœ‰ batchï¼ˆå’Œè®­ç»ƒä¸€è‡´ï¼šé€€åŒ–â†’è¿˜åŸï¼‰
    y_preds, y_trues = [], []
    stats_for_eval = None

    n_batches = len(loader)
    t0 = time.time()
    with torch.no_grad():
        for i, features in enumerate(loader, 1):
            # ç§»åˆ°è®¾å¤‡ï¼›dataset é»˜è®¤å·²ç»æ˜¯å¼ é‡å­—å…¸
            for k, v in list(features.items()):
                if torch.is_tensor(v):
                    features[k] = v.to(device, non_blocking=True)

            # å–çœŸå€¼ï¼ˆæ¨èç”¨ target_trafficï¼›å¦‚æœæ²¡æœ‰å°±ç”¨ data.squeeze(-1)ï¼‰
            if 'target_traffic' in features:
                y_true = features['target_traffic']              # [B, A, T]
            else:
                data = features['data']                           # [B, A, T, 1]
                y_true = data.squeeze(-1)

            # é€€åŒ–æ—¶é—´æ­¥
            B = y_true.shape[0]
            t = torch.randint(0, diffusion.max_step, [B], dtype=torch.int64, device=device)

            # é€€åŒ–è¾“å…¥ï¼ˆè®­ç»ƒé‡Œæ˜¯å¯¹ data åšçš„ï¼‰
            x0 = features['data'] if 'data' in features else y_true.unsqueeze(-1)
            x_t = diffusion.degrade_fn(x0, t, params.task_id)

            # æ¨¡å‹è¿˜åŸ
            y_pred = model(x_t, t, features['cond'])
            if y_pred.ndim == 4 and y_pred.shape[-1] == 1:
                y_pred = y_pred.squeeze(-1)

            y_preds.append(y_pred.detach().cpu())
            y_trues.append(y_true.detach().cpu())

            if stats_for_eval is None and 'stats' in features:
                stats_for_eval = features['stats']  # dict: {'mean':..., 'std':...}

            if args.limit and sum(p.size(0) for p in y_preds) >= args.limit:
                break

            if i % 20 == 0 or i == n_batches:
                done = sum(p.size(0) for p in y_preds)
                print(f"[{i}/{n_batches}] accumulated {done} samples...")

    import numpy as np
    y_pred_all = torch.cat(y_preds, dim=0).numpy()  # [N, A, T]
    y_true_all = torch.cat(y_trues, dim=0).numpy()  # [N, A, T]

    # è¯„ä¼°
    res = evaluate_forecast(
        y_pred_all, y_true_all,
        stats=stats_for_eval,
        layout='BAT',
        per_app=True,
        per_horizon=True
    )

    # æ‰“å°æ‘˜è¦
    print("\n================ Evaluation Summary ================")
    print(summarize_eval(res))
    print("====================================================")
    print(f"è€—æ—¶: {time.time() - t0:.1f}s  æ ·æœ¬æ•°: {y_true_all.shape[0]}")

    # ä¿å­˜ç»“æœ
    os.makedirs(args.out_dir, exist_ok=True)
    out_json = os.path.join(args.out_dir, f"eval_{args.split}.json")
    import json as _json
    with open(out_json, "w", encoding="utf-8") as f:
        _json.dump(res, f, ensure_ascii=False, indent=2)
    print(f"ğŸ“„ Saved metrics -> {out_json}")

def main():
    p = argparse.ArgumentParser("Evaluate tfdiff model")
    p.add_argument("--task_id", type=int, default=4, help="0/1/2/3/4 -> WiFi/FMCW/MIMO/EEG/Traffic")
    p.add_argument("--ckpt", type=str, default=None, help="checkpoint è·¯å¾„ï¼ˆé»˜è®¤ä½¿ç”¨ {model_dir}/weights.ptï¼‰")
    p.add_argument("--split", type=str, default="test", choices=["val", "test"], help="è¯„ä¼°æ•°æ®åˆ’åˆ†")
    p.add_argument("--batch_size", type=int, default=None, help="è¯„ä¼° batch sizeï¼ˆé»˜è®¤ç”¨ params.inference_batch_sizeï¼‰")
    p.add_argument("--num_workers", type=int, default=0, help="DataLoader workersï¼ˆWindows æ¨è 0~2ï¼‰")
    p.add_argument("--device", type=str, default="cuda", choices=["cuda", "cpu"], help="è¯„ä¼°è®¾å¤‡")
    p.add_argument("--limit", type=int, default=None, help="ä»…è¯„ä¼°å‰ N æ¡æ ·æœ¬ï¼ˆè°ƒè¯•ç”¨ï¼‰")
    p.add_argument("--out_dir", type=str, default="./eval_out", help="æŒ‡æ ‡ä¿å­˜ç›®å½•")
    args = p.parse_args()
    run_eval(args)

if __name__ == "__main__":
    main()
