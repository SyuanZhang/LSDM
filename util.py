import os
import argparse
import time
import torch
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from torch.utils.data import DataLoader
from scipy import stats
import json

# å¯¼å…¥è®­ç»ƒä»£ç ä¸­çš„æ¨¡å—
from params import all_params
from wifi_model import tfdiff_WiFi
from model import ConditionalUNet
from diffusion import SignalDiffusion, GaussianDiffusion
from dataset import from_path

# ğŸ”§ æ–°å¢ï¼šå¯¼å…¥ä¿®å¤ç‰ˆçš„æ‰©æ•£æ¨¡å‹
try:
    from wifi_model import (
        DiffusionTimeSeriesModel, 
        MaskedDiffusionConfig, 
        create_masked_diffusion_model,
        MaskedDiffusionTrainer
    )
    MASKED_DIFFUSION_AVAILABLE = True
    print("âœ… Masked diffusion model available")
except ImportError as e:
    print(f"âš ï¸ Masked diffusion model not available: {e}")
    MASKED_DIFFUSION_AVAILABLE = False

# è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒå’Œç»˜å›¾æ ·å¼
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
sns.set_style("whitegrid")
plt.rcParams['figure.dpi'] = 300

def get_device(device_str='cuda'):
    """è·å–è®¾å¤‡"""
    if device_str == 'cpu':
        return torch.device('cpu')
    elif torch.cuda.is_available():
        return torch.device('cuda')
    else:
        print("CUDA not available, falling back to CPU")
        return torch.device('cpu')

def seed_everything(seed=42):
    """è®¾ç½®éšæœºç§å­"""
    import random
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)

def detect_model_type(checkpoint_path):
    """ğŸ”§ å¢å¼ºçš„æ¨¡å‹ç±»å‹æ£€æµ‹ï¼Œæ”¯æŒæ›´å¤šæ¨¡å‹ç±»å‹"""
    print(f"Detecting model type from checkpoint: {checkpoint_path}")
    
    try:
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
        
        # å¤„ç†ä¸åŒçš„æ£€æŸ¥ç‚¹æ ¼å¼
        if isinstance(checkpoint, dict):
            if 'model' in checkpoint:
                state_dict = checkpoint['model']
            elif 'model_state_dict' in checkpoint:
                state_dict = checkpoint['model_state_dict']
            else:
                state_dict = checkpoint
        else:
            state_dict = checkpoint
        
        # æ£€æŸ¥å…³é”®çš„æ¨¡å‹å‚æ•°æ¥åˆ¤æ–­æ¨¡å‹ç±»å‹
        keys = list(state_dict.keys())
        
        # æ£€æŸ¥ä¿®å¤ç‰ˆæ‰©æ•£æ¨¡å‹
        masked_diffusion_keys = [
            'timestep_embedder.mlp.0.weight',
            'condition_embedder.condition_proj.0.weight',
            'dit_blocks.0.adaLN_modulation.1.weight'
        ]
        
        # å¦‚æœæœ‰è¿™äº›å…³é”®å­—ï¼Œè¯´æ˜æ˜¯ConditionalUNet
        conditional_unet_keys = ['time_embed.0.weight', 'down_blocks.0.time_mlp.weight', 'up_blocks.0.time_mlp.weight']
        
        # å¦‚æœæœ‰è¿™äº›å…³é”®å­—ï¼Œè¯´æ˜æ˜¯tfdiff_WiFi
        tfdiff_wifi_keys = ['p_embed.projection.weight', 'blocks.0.norm1.weight', 'final_layer.norm.weight']
        
        has_masked_diffusion = any(key in keys for key in masked_diffusion_keys)
        has_conditional_unet = any(key in keys for key in conditional_unet_keys)
        has_tfdiff_wifi = any(key in keys for key in tfdiff_wifi_keys)
        
        if has_masked_diffusion:
            print("ğŸ” Detected model type: MaskedDiffusion")
            return 'MaskedDiffusion'
        elif has_conditional_unet:
            print("ğŸ” Detected model type: ConditionalUNet")
            return 'ConditionalUNet'
        elif has_tfdiff_wifi:
            print("ğŸ” Detected model type: tfdiff_WiFi")
            return 'tfdiff_WiFi'
        else:
            print("âš ï¸  Could not detect model type, defaulting to ConditionalUNet")
            print(f"Available keys (first 10): {keys[:10]}")
            return 'ConditionalUNet'
            
    except Exception as e:
        print(f"âŒ Error detecting model type: {e}")
        print("Defaulting to ConditionalUNet")
        return 'ConditionalUNet'

def load_model_checkpoint(model, checkpoint_path, device):
    """ğŸ”§ æ”¹è¿›çš„æ£€æŸ¥ç‚¹åŠ è½½ï¼Œæ”¯æŒä¸å®Œå…¨åŒ¹é…"""
    if not os.path.exists(checkpoint_path):
        raise FileNotFoundError(f"Checkpoint not found: {checkpoint_path}")
    
    print(f"Loading checkpoint from: {checkpoint_path}")
    checkpoint = torch.load(checkpoint_path, map_location=device)
    
    # å¤„ç†ä¸åŒçš„æ£€æŸ¥ç‚¹æ ¼å¼
    if isinstance(checkpoint, dict):
        if 'model' in checkpoint:
            state_dict = checkpoint['model']
        elif 'model_state_dict' in checkpoint:
            state_dict = checkpoint['model_state_dict']
        else:
            state_dict = checkpoint
    else:
        state_dict = checkpoint
    
    # å¤„ç† DistributedDataParallel çš„æƒé‡
    new_state_dict = {}
    for k, v in state_dict.items():
        if k.startswith('module.'):
            new_state_dict[k[7:]] = v  # ç§»é™¤ 'module.' å‰ç¼€
        else:
            new_state_dict[k] = v
    
    try:
        model.load_state_dict(new_state_dict, strict=True)
        print("âœ… Checkpoint loaded successfully")
    except RuntimeError as e:
        print(f"âŒ Error loading checkpoint with strict=True: {e}")
        print("ğŸ”§ Trying to load with strict=False...")
        missing_keys, unexpected_keys = model.load_state_dict(new_state_dict, strict=False)
        if missing_keys:
            print(f"âš ï¸  Missing keys: {len(missing_keys)} keys")
            print(f"First few missing keys: {missing_keys[:5]}")
        if unexpected_keys:
            print(f"âš ï¸  Unexpected keys: {len(unexpected_keys)} keys")
            print(f"First few unexpected keys: {unexpected_keys[:5]}")
        print("âœ… Checkpoint loaded with warnings")

def create_diffusion(params, device):
    """åˆ›å»ºæ‰©æ•£æ¨¡å‹"""
    if hasattr(params, 'signal_diffusion') and params.signal_diffusion:
        diffusion = SignalDiffusion(params)
    else:
        diffusion = GaussianDiffusion(params)
    return diffusion.to(device)

def compute_metrics(y_pred, y_true):
    """è®¡ç®—è¯„ä¼°æŒ‡æ ‡ï¼ˆä¿®å¤JSONåºåˆ—åŒ–é—®é¢˜ï¼‰"""
    # ç¡®ä¿è¾“å…¥æ˜¯numpyæ•°ç»„
    if torch.is_tensor(y_pred):
        y_pred = y_pred.detach().cpu().numpy()
    if torch.is_tensor(y_true):
        y_true = y_true.detach().cpu().numpy()
    
    # ğŸ”§ å¤„ç†NaNå€¼
    if np.isnan(y_pred).any() or np.isnan(y_true).any():
        print("âš ï¸ NaN values detected in predictions or targets")
        # ç§»é™¤NaNå€¼å¯¹åº”çš„ä½ç½®
        valid_mask = ~(np.isnan(y_pred) | np.isnan(y_true))
        if valid_mask.sum() == 0:
            print("âŒ All values are NaN!")
            return {
                'MSE': float('inf'),
                'MAE': float('inf'),
                'RMSE': float('inf'),
                'MAPE': float('inf'),
                'Correlation': 0.0,
                'R2_Score': 0.0
            }
        y_pred = y_pred[valid_mask]
        y_true = y_true[valid_mask]
    
    # è®¡ç®—å„ç§æŒ‡æ ‡
    mse = np.mean((y_pred - y_true) ** 2)
    mae = np.mean(np.abs(y_pred - y_true))
    rmse = np.sqrt(mse)
    
    # é¿å…é™¤é›¶é”™è¯¯
    y_true_nonzero = y_true + 1e-8
    mape = np.mean(np.abs((y_true - y_pred) / y_true_nonzero)) * 100
    
    # ç›¸å…³ç³»æ•°
    if np.std(y_pred) > 1e-8 and np.std(y_true) > 1e-8:
        correlation = np.corrcoef(y_pred.flatten(), y_true.flatten())[0, 1]
        if np.isnan(correlation):
            correlation = 0.0
    else:
        correlation = 0.0
    
    # RÂ²å†³å®šç³»æ•°
    ss_res = np.sum((y_true - y_pred) ** 2)
    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)
    r2_score = 1 - (ss_res / (ss_tot + 1e-8))
    
    # å…³é”®ä¿®æ”¹ï¼šå°†æ‰€æœ‰numpyç±»å‹è½¬æ¢ä¸ºPythonåŸç”Ÿç±»å‹
    return {
        'MSE': float(mse),
        'MAE': float(mae), 
        'RMSE': float(rmse),
        'MAPE': float(mape),
        'Correlation': float(correlation),
        'R2_Score': float(r2_score)
    }

def build_params(task_id, device_str='cuda', pred_len=20):
    """ğŸ”§ æ”¹è¿›çš„å‚æ•°æ„å»ºå‡½æ•°ï¼Œæ”¯æŒä¿®å¤ç‰ˆæ‰©æ•£æ¨¡å‹"""
    if task_id == 4:
        from params import AttrDict
        import numpy as np
        
        # ğŸ”§ æ ¹æ®é¢„æµ‹é•¿åº¦åŠ¨æ€è°ƒæ•´å‚æ•°
        total_seq_len = 168  # æ€»åºåˆ—é•¿åº¦
        input_seq_len = total_seq_len - pred_len  # è¾“å…¥åºåˆ—é•¿åº¦
        
        params = AttrDict(
            task_id=4,
            log_dir='./log/traffic',
            model_dir='./model/traffic_prediction',  
            data_dir=['./dataset/traffic'],
            traffic_path='traffic_data_new.npz',
            embedding_path='environment_embeddings.npz',
            max_iter=10000,
            batch_size=64,
            learning_rate=1e-4,
            max_grad_norm=0.5,
            inference_batch_size=16,
            robust_sampling=True,
            
            # ğŸ”§ é¢„æµ‹ä»»åŠ¡ç›¸å…³å‚æ•°
            pred_len=pred_len,
            seq_len=input_seq_len,  
            input_seq_len=input_seq_len,
            total_seq_len=total_seq_len,
            
            sample_rate=20,
            input_dim=20,
            output_dim=20,
            extra_dim=[128],
            cond_dim=input_seq_len,  
            embed_dim=128,
            hidden_dim=128,
            num_heads=4,
            num_block=8,
            dropout=0.1,
            mlp_ratio=4.0,
            learn_tfdiff=False,
            max_step=1000,
            signal_diffusion=True,
            blur_schedule=((1e-5**2) * np.ones(1000)).tolist(),
            noise_schedule=np.linspace(1e-4, 0.02, 1000).tolist(),
            device=device_str,
            
            prediction_mode=True,  
            
            # ğŸ”§ ä¸ºä¿®å¤ç‰ˆæ‰©æ•£æ¨¡å‹æ·»åŠ å‚æ•°
            mask_length=3,
            mask_strategies=['prefix', 'suffix', 'random'],
            mask_lengths=[1, 2, 3, 4, 5],
            mask_weight=1.0,
            unmask_weight=0.1,
            num_timesteps=1000,
            depth=4,
        )
        
        print(f"ğŸ“Š Task {task_id} Configuration:")
        print(f"  â€¢ Total sequence length: {total_seq_len}")
        print(f"  â€¢ Input sequence length: {input_seq_len}")
        print(f"  â€¢ Prediction length: {pred_len}")
        print(f"  â€¢ Condition dimension: {input_seq_len}")
        
        return params
    else:
        params = all_params[task_id]
        # ä¸ºå…¶ä»–ä»»åŠ¡ä¹Ÿæ·»åŠ é¢„æµ‹æ¨¡å¼æ”¯æŒ
        if pred_len is not None and pred_len > 0:
            params.pred_len = pred_len
            params.prediction_mode = True
        return params

def evaluate_model(model, diffusion, dataloader, device, params, num_samples=None):
    """ğŸ”§ æ”¹è¿›çš„æ¨¡å‹è¯„ä¼°å‡½æ•°ï¼Œæ”¯æŒå¤šç§æ¨¡å‹ç±»å‹"""
    model.eval()
    
    all_predictions = []
    all_targets = []
    
    total_samples = 0
    start_time = time.time()
    
    print("Starting evaluation...")
    
    # ğŸ”§ æ£€æŸ¥æ¨¡å‹ç±»å‹
    model_type = type(model).__name__
    print(f"Model type detected: {model_type}")
    
    with torch.no_grad():
        for batch_idx, batch in enumerate(dataloader):
            try:
                # å°†æ•°æ®ç§»åˆ°è®¾å¤‡ä¸Š
                if isinstance(batch, dict):
                    for key in batch:
                        if torch.is_tensor(batch[key]):
                            batch[key] = batch[key].to(device)
                    
                    # è·å–è¾“å…¥æ•°æ®å’Œç›®æ ‡
                    if 'data' in batch:
                        x = batch['data']
                        if x.dim() == 4 and x.size(-1) == 1:
                            target = x.squeeze(-1)  # [B, A, T]
                        else:
                            target = x
                    elif 'target_traffic' in batch:
                        target = batch['target_traffic']
                        x = target.unsqueeze(-1) if target.dim() == 3 else target
                    else:
                        print("Warning: Could not find data or target_traffic in batch")
                        continue
                    
                    # æ¡ä»¶ä¿¡æ¯
                    cond = batch.get('cond', None)
                    
                else:
                    # å¦‚æœbatchä¸æ˜¯å­—å…¸ï¼Œå‡è®¾æ˜¯tensor
                    x = batch.to(device)
                    target = x.squeeze(-1) if x.dim() == 4 else x
                    cond = None
                
                batch_size = target.size(0)
                
                # ğŸ”§ æ ¹æ®æ¨¡å‹ç±»å‹è¿›è¡Œæ¨ç†
                if 'MaskedDiffusion' in model_type or 'DiffusionTimeSeriesModel' in model_type:
                    # ä¿®å¤ç‰ˆæ‰©æ•£æ¨¡å‹
                    if hasattr(model, 'num_timesteps'):
                        t = torch.randint(0, model.num_timesteps, (batch_size,), device=device)
                    else:
                        t = torch.randint(0, 50, (batch_size,), device=device)  # é»˜è®¤å€¼
                    
                    # ä¿®å¤ç‰ˆæ¨¡å‹çš„è°ƒç”¨æ–¹å¼
                    pred, mask = model(x, t, cond)
                    
                elif 'ConditionalUNet' in model_type:
                    # ConditionalUNetæ¨¡å‹
                    t = torch.randint(0, diffusion.max_step, (batch_size,), device=device)
                    if cond is not None:
                        pred = model(x, t, cond)
                    else:
                        pred = model(x, t)
                        
                else:
                    # tfdiff_WiFiæ¨¡å‹
                    t = torch.randint(0, diffusion.max_step, (batch_size,), device=device)
                    if cond is not None:
                        pred = model(x, t, cond)
                    else:
                        pred = model(x, t)
                
                # å¤„ç†é¢„æµ‹ç»“æœçš„ç»´åº¦
                if pred.dim() == 4 and pred.size(-1) == 1:
                    pred = pred.squeeze(-1)
                
                # ğŸ”§ æ£€æŸ¥é¢„æµ‹ç»“æœçš„æœ‰æ•ˆæ€§
                if torch.isnan(pred).any() or torch.isinf(pred).any():
                    print(f"âš ï¸ Invalid predictions in batch {batch_idx}, skipping")
                    continue
                
                # æ”¶é›†ç»“æœ
                all_predictions.append(pred.cpu())
                all_targets.append(target.cpu())
                
                total_samples += batch_size
                
                if (batch_idx + 1) % 10 == 0:
                    elapsed = time.time() - start_time
                    print(f"Processed {batch_idx + 1} batches, {total_samples} samples, "
                          f"time: {elapsed:.2f}s")
                
                # å¦‚æœæŒ‡å®šäº†æ ·æœ¬æ•°é™åˆ¶
                if num_samples is not None and total_samples >= num_samples:
                    break
                    
            except Exception as e:
                print(f"âŒ Error processing batch {batch_idx}: {e}")
                import traceback
                traceback.print_exc()
                # è·³è¿‡è¿™ä¸ªbatch
                continue
    
    if not all_predictions:
        raise RuntimeError("No successful predictions were made!")
    
    # åˆå¹¶æ‰€æœ‰é¢„æµ‹å’Œç›®æ ‡
    all_predictions = torch.cat(all_predictions, dim=0)
    all_targets = torch.cat(all_targets, dim=0)
    
    print(f"Evaluation completed. Total samples: {total_samples}")
    print(f"Prediction shape: {all_predictions.shape}")
    print(f"Target shape: {all_targets.shape}")
    
    # è®¡ç®—æŒ‡æ ‡
    metrics = compute_metrics(all_predictions, all_targets)
    
    return metrics, all_predictions, all_targets

def create_comprehensive_visualizations(predictions, targets, metrics, output_dir, task_id):
    """åˆ›å»ºå…¨é¢çš„å¯è§†åŒ–å›¾è¡¨"""
    print("Creating comprehensive visualizations...")
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    vis_dir = os.path.join(output_dir, 'visualizations')
    os.makedirs(vis_dir, exist_ok=True)
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    if torch.is_tensor(predictions):
        predictions = predictions.detach().cpu().numpy()
    if torch.is_tensor(targets):
        targets = targets.detach().cpu().numpy()
    
    print(f"Data shape - Predictions: {predictions.shape}, Targets: {targets.shape}")
    
    # 1. é¢„æµ‹æ•ˆæœæ€»è§ˆ
    create_prediction_overview(predictions, targets, metrics, vis_dir)
    
    # 2. è¯¦ç»†çš„æ—¶é—´åºåˆ—é¢„æµ‹å¯¹æ¯”
    create_detailed_time_series(predictions, targets, vis_dir)
    
    # 3. é¢„æµ‹ç²¾åº¦åˆ†æ
    create_accuracy_analysis(predictions, targets, vis_dir)
    
    # 4. è¯¯å·®åˆ†æ
    create_error_analysis(predictions, targets, vis_dir)
    
    # 5. ç»Ÿè®¡åˆ†å¸ƒå¯¹æ¯”
    create_distribution_comparison(predictions, targets, vis_dir)
    
    # 6. æ€§èƒ½æŒ‡æ ‡å¯è§†åŒ–
    create_metrics_dashboard(metrics, vis_dir)
    
    # 7. å¦‚æœæ˜¯å¤šç»´æ•°æ®ï¼Œåˆ›å»ºçƒ­åŠ›å›¾
    if predictions.ndim >= 3:
        create_multidimensional_analysis(predictions, targets, vis_dir)
    
    print(f"All visualizations saved to: {vis_dir}")

def create_prediction_overview(predictions, targets, metrics, output_dir):
    """åˆ›å»ºé¢„æµ‹æ•ˆæœæ€»è§ˆå›¾"""
    fig = plt.figure(figsize=(20, 12))
    
    # ğŸ”§ ä¿®æ”¹ï¼šæ ¹æ®å®é™…éœ€è¦çš„å­å›¾æ•°é‡è°ƒæ•´ç½‘æ ¼å¤§å°
    n_time_series_examples = min(3, predictions.shape[0])  # æœ€å¤šæ˜¾ç¤º3ä¸ªæ—¶é—´åºåˆ—ä¾‹å­
    grid_rows = max(3, n_time_series_examples + 1)  # è‡³å°‘3è¡Œï¼Œç¡®ä¿æœ‰è¶³å¤Ÿç©ºé—´
    
    gs = fig.add_gridspec(grid_rows, 4, hspace=0.3, wspace=0.3)
    
    # 1. é¢„æµ‹vsçœŸå®å€¼æ•£ç‚¹å›¾
    ax1 = fig.add_subplot(gs[0, 0:2])
    n_samples = min(10000, predictions.size)
    indices = np.random.choice(predictions.size, n_samples, replace=False)
    pred_flat = predictions.flatten()[indices]
    true_flat = targets.flatten()[indices]
    
    scatter = ax1.scatter(true_flat, pred_flat, alpha=0.6, s=2, c=pred_flat, cmap='viridis')
    min_val, max_val = min(true_flat.min(), pred_flat.min()), max(true_flat.max(), pred_flat.max())
    ax1.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect Prediction')
    ax1.set_xlabel('True Values')
    ax1.set_ylabel('Predicted Values')
    ax1.set_title('Prediction vs True Values')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    plt.colorbar(scatter, ax=ax1, label='Predicted Value')
    
    # 2. ç›¸å…³æ€§å’ŒRÂ²æ˜¾ç¤º
    ax2 = fig.add_subplot(gs[0, 2])
    ax2.text(0.1, 0.8, f'Correlation: {metrics["Correlation"]:.4f}', fontsize=14, transform=ax2.transAxes)
    ax2.text(0.1, 0.6, f'RÂ² Score: {metrics["R2_Score"]:.4f}', fontsize=14, transform=ax2.transAxes)
    ax2.text(0.1, 0.4, f'RMSE: {metrics["RMSE"]:.4f}', fontsize=14, transform=ax2.transAxes)
    ax2.text(0.1, 0.2, f'MAE: {metrics["MAE"]:.4f}', fontsize=14, transform=ax2.transAxes)
    ax2.set_xlim(0, 1)
    ax2.set_ylim(0, 1)
    ax2.set_title('Key Metrics')
    ax2.axis('off')
    
    # 3. è¯¯å·®åˆ†å¸ƒ
    ax3 = fig.add_subplot(gs[0, 3])
    errors = (predictions - targets).flatten()
    ax3.hist(errors, bins=50, alpha=0.7, edgecolor='black', color='skyblue')
    ax3.axvline(errors.mean(), color='red', linestyle='--', label=f'Mean: {errors.mean():.4f}')
    ax3.set_xlabel('Prediction Error')
    ax3.set_ylabel('Frequency')
    ax3.set_title('Error Distribution')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # 4. æ—¶é—´åºåˆ—ç¤ºä¾‹
    if predictions.ndim >= 2:
        for i in range(n_time_series_examples):
            # ğŸ”§ ä¿®æ”¹ï¼šç¡®ä¿ç´¢å¼•ä¸ä¼šè¶…å‡ºèŒƒå›´
            row_idx = i + 1
            if row_idx < grid_rows:  # ç¡®ä¿ä¸è¶…å‡ºç½‘æ ¼èŒƒå›´
                ax = fig.add_subplot(gs[row_idx, :2])
                
                if predictions.ndim == 3:  # [samples, features, time]
                    # ğŸ”§ æ”¹è¿›ï¼šå¯¹äºå¤šç»´æ•°æ®ï¼Œæ˜¾ç¤ºæ‰€æœ‰ç‰¹å¾çš„å¹³å‡å€¼
                    pred_series = predictions[i].mean(axis=0)
                    true_series = targets[i].mean(axis=0)
                    
                else:  # [samples, time]
                    pred_series = predictions[i]
                    true_series = targets[i]
                
                time_steps = np.arange(len(pred_series))
                ax.plot(time_steps, true_series, 'b-', linewidth=2, alpha=0.8, label='Ground Truth')
                ax.plot(time_steps, pred_series, 'r--', linewidth=2, alpha=0.8, label='Prediction')
                ax.fill_between(time_steps, true_series, pred_series, alpha=0.3, color='gray')
                
                ax.set_title(f'Sample {i+1} - Time Series Comparison')
                ax.set_xlabel('Time Step')
                ax.set_ylabel('Value')
                ax.legend()
                ax.grid(True, alpha=0.3)
    
    # 5. æ•´ä½“è¯¯å·®è¶‹åŠ¿ï¼ˆå¦‚æœæ˜¯æ—¶é—´åºåˆ—æ•°æ®ï¼‰
    if predictions.ndim >= 2 and predictions.shape[-1] > 1:
        # ğŸ”§ ä¿®æ”¹ï¼šä½¿ç”¨å‰©ä½™çš„ç½‘æ ¼ç©ºé—´
        if grid_rows > 2:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„è¡Œæ•°
            ax5 = fig.add_subplot(gs[1:, 2:])
            
            # è®¡ç®—æ¯ä¸ªæ—¶é—´æ­¥çš„å¹³å‡ç»å¯¹è¯¯å·®
            if predictions.ndim == 3:
                timestep_errors = np.abs(predictions - targets).mean(axis=(0, 1))
            else:
                timestep_errors = np.abs(predictions - targets).mean(axis=0)
            
            time_steps = np.arange(len(timestep_errors))
            ax5.plot(time_steps, timestep_errors, 'g-', linewidth=3, marker='o', markersize=4)
            ax5.set_xlabel('Time Step')
            ax5.set_ylabel('Mean Absolute Error')
            ax5.set_title('Prediction Error by Time Step')
            ax5.grid(True, alpha=0.3)
            
            # æ·»åŠ è¶‹åŠ¿çº¿
            if len(time_steps) > 1:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®ç‚¹æ¥æ‹Ÿåˆè¶‹åŠ¿çº¿
                z = np.polyfit(time_steps, timestep_errors, 1)
                p = np.poly1d(z)
                ax5.plot(time_steps, p(time_steps), "r--", alpha=0.8, 
                        label=f'Trend (slope: {z[0]:.6f})')
                ax5.legend()
    
    plt.suptitle(f'Prediction Performance Overview - Shape {predictions.shape}', fontsize=16, y=0.98)
    plt.savefig(os.path.join(output_dir, 'prediction_overview.png'), dpi=300, bbox_inches='tight')
    plt.close()

def create_detailed_time_series(predictions, targets, output_dir, n_examples=8):
    """åˆ›å»ºè¯¦ç»†çš„æ—¶é—´åºåˆ—å¯¹æ¯”å›¾"""
    if predictions.ndim < 2:
        return
    
    n_samples = min(predictions.shape[0], n_examples)
    fig, axes = plt.subplots((n_samples + 1) // 2, 2, figsize=(20, 5 * (n_samples + 1) // 2))
    
    # ğŸ”§ ç¡®ä¿axesæ˜¯æ•°ç»„æ ¼å¼
    if n_samples <= 2:
        if n_samples == 1:
            axes = [axes]
        else:
            axes = axes.flatten() if hasattr(axes, 'flatten') else [axes]
    else:
        axes = axes.flatten()
    
    # é€‰æ‹©æœ‰ä»£è¡¨æ€§çš„æ ·æœ¬ï¼ˆåŒ…æ‹¬æœ€å¥½å’Œæœ€å·®çš„é¢„æµ‹ï¼‰
    sample_errors = []
    for i in range(min(50, predictions.shape[0])):  # åªè®¡ç®—å‰50ä¸ªæ ·æœ¬çš„è¯¯å·®ï¼Œé¿å…è®¡ç®—é‡è¿‡å¤§
        if predictions.ndim == 3:
            error = np.mean(np.abs(predictions[i] - targets[i]))
        else:
            error = np.mean(np.abs(predictions[i] - targets[i]))
        sample_errors.append((error, i))
    
    sample_errors.sort()
    # é€‰æ‹©æœ€å¥½çš„å‡ ä¸ªå’Œæœ€å·®çš„å‡ ä¸ªï¼Œä»¥åŠä¸€äº›ä¸­ç­‰çš„
    best_indices = [idx for _, idx in sample_errors[:max(1, n_samples//3)]]
    worst_indices = [idx for _, idx in sample_errors[-max(1, n_samples//3):]]
    mid_start = len(sample_errors)//2 - max(1, n_samples//6)
    mid_end = len(sample_errors)//2 + max(1, n_samples//6)
    mid_indices = [idx for _, idx in sample_errors[mid_start:mid_end]]
    
    selected_indices = (best_indices + mid_indices + worst_indices)[:n_samples]
    
    for i, sample_idx in enumerate(selected_indices):
        ax = axes[i]
        
        if predictions.ndim == 3:  # [samples, features, time]
            # æ˜¾ç¤ºæ‰€æœ‰ç‰¹å¾çš„å¹³å‡å€¼
            pred_series = predictions[sample_idx].mean(axis=0)
            true_series = targets[sample_idx].mean(axis=0)
        else:  # [samples, time]
            pred_series = predictions[sample_idx]
            true_series = targets[sample_idx]
        
        time_steps = np.arange(len(pred_series))
        
        # ç»˜åˆ¶é¢„æµ‹å’ŒçœŸå®å€¼
        ax.plot(time_steps, true_series, 'b-', linewidth=2.5, alpha=0.8, label='Ground Truth')
        ax.plot(time_steps, pred_series, 'r--', linewidth=2, alpha=0.9, label='Prediction')
        
        # å¡«å……è¯¯å·®åŒºåŸŸ
        ax.fill_between(time_steps, true_series, pred_series, alpha=0.3, color='gray', label='Error')
        
        # è®¡ç®—å¹¶æ˜¾ç¤ºè¯¥æ ·æœ¬çš„è¯¯å·®
        mae = np.mean(np.abs(pred_series - true_series))
        rmse = np.sqrt(np.mean((pred_series - true_series) ** 2))
        
        ax.set_title(f'Sample {sample_idx + 1} (MAE: {mae:.4f}, RMSE: {rmse:.4f})')
        ax.set_xlabel('Time Step')
        ax.set_ylabel('Value')
        ax.legend()
        ax.grid(True, alpha=0.3)
    
    # éšè—å¤šä½™çš„å­å›¾
    for i in range(len(selected_indices), len(axes)):
        axes[i].set_visible(False)
    
    plt.suptitle('Detailed Time Series Prediction Comparison', fontsize=16)
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'detailed_time_series.png'), dpi=300, bbox_inches='tight')
    plt.close()

def create_accuracy_analysis(predictions, targets, output_dir):
    """åˆ›å»ºé¢„æµ‹ç²¾åº¦åˆ†æ"""
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    axes = axes.flatten()
    
    # 1. ç»å¯¹è¯¯å·®vsé¢„æµ‹å€¼
    pred_flat = predictions.flatten()
    abs_errors = np.abs(predictions.flatten() - targets.flatten())
    
    # éšæœºé‡‡æ ·ä»¥é¿å…è¿‡å¤šçš„ç‚¹
    n_samples = min(10000, len(pred_flat))
    indices = np.random.choice(len(pred_flat), n_samples, replace=False)
    
    axes[0].scatter(pred_flat[indices], abs_errors[indices], alpha=0.5, s=1)
    axes[0].set_xlabel('Predicted Values')
    axes[0].set_ylabel('Absolute Error')
    axes[0].set_title('Absolute Error vs Predicted Values')
    axes[0].grid(True, alpha=0.3)
    
    # 2. ç›¸å¯¹è¯¯å·®åˆ†å¸ƒ
    relative_errors = np.abs((predictions.flatten() - targets.flatten()) / (targets.flatten() + 1e-8)) * 100
    relative_errors = relative_errors[relative_errors < 200]  # ç§»é™¤å¼‚å¸¸å€¼
    
    axes[1].hist(relative_errors, bins=50, alpha=0.7, edgecolor='black')
    axes[1].set_xlabel('Relative Error (%)')
    axes[1].set_ylabel('Frequency')
    axes[1].set_title('Relative Error Distribution')
    axes[1].axvline(np.median(relative_errors), color='red', linestyle='--', 
                   label=f'Median: {np.median(relative_errors):.2f}%')
    axes[1].legend()
    axes[1].grid(True, alpha=0.3)
    
    # 3. è¯¯å·®ç´¯ç§¯åˆ†å¸ƒå‡½æ•°
    errors_sorted = np.sort(abs_errors)
    cdf = np.arange(1, len(errors_sorted) + 1) / len(errors_sorted)
    
    axes[2].plot(errors_sorted, cdf, linewidth=2)
    axes[2].set_xlabel('Absolute Error')
    axes[2].set_ylabel('Cumulative Probability')
    axes[2].set_title('Error Cumulative Distribution')
    axes[2].grid(True, alpha=0.3)
    
    # 4. çœŸå®å€¼vsç»å¯¹è¯¯å·®
    true_flat = targets.flatten()
    axes[3].scatter(true_flat[indices], abs_errors[indices], alpha=0.5, s=1)
    axes[3].set_xlabel('True Values')
    axes[3].set_ylabel('Absolute Error')
    axes[3].set_title('Absolute Error vs True Values')
    axes[3].grid(True, alpha=0.3)
    
    # 5. é¢„æµ‹å€¼åˆ†å¸ƒvsçœŸå®å€¼åˆ†å¸ƒ
    axes[4].hist(true_flat, bins=50, alpha=0.7, label='True Values', color='blue', density=True)
    axes[4].hist(pred_flat, bins=50, alpha=0.7, label='Predictions', color='red', density=True)
    axes[4].set_xlabel('Value')
    axes[4].set_ylabel('Density')
    axes[4].set_title('Value Distributions')
    axes[4].legend()
    axes[4].grid(True, alpha=0.3)
    
    # 6. ç™¾åˆ†ä½æ•°å¯¹æ¯”
    percentiles = np.arange(0, 101, 5)
    true_percentiles = np.percentile(true_flat, percentiles)
    pred_percentiles = np.percentile(pred_flat, percentiles)
    
    axes[5].plot(percentiles, true_percentiles, 'b-', linewidth=2, label='True Values', marker='o')
    axes[5].plot(percentiles, pred_percentiles, 'r--', linewidth=2, label='Predictions', marker='s')
    axes[5].set_xlabel('Percentile')
    axes[5].set_ylabel('Value')
    axes[5].set_title('Percentile Comparison')
    axes[5].legend()
    axes[5].grid(True, alpha=0.3)
    
    plt.suptitle('Prediction Accuracy Analysis', fontsize=16)
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'accuracy_analysis.png'), dpi=300, bbox_inches='tight')
    plt.close()

def create_error_analysis(predictions, targets, output_dir):
    """åˆ›å»ºè¯¦ç»†çš„è¯¯å·®åˆ†æ"""
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    axes = axes.flatten()
    
    errors = predictions.flatten() - targets.flatten()
    
    # 1. è¯¯å·®çš„æ­£æ€æ€§æ£€éªŒå›¾
    axes[0].hist(errors, bins=50, density=True, alpha=0.7, color='skyblue', edgecolor='black')
    
    # æ‹Ÿåˆæ­£æ€åˆ†å¸ƒ
    mu, std = stats.norm.fit(errors)
    xmin, xmax = axes[0].get_xlim()
    x = np.linspace(xmin, xmax, 100)
    p = stats.norm.pdf(x, mu, std)
    axes[0].plot(x, p, 'r-', linewidth=2, label=f'Normal fit (Î¼={mu:.4f}, Ïƒ={std:.4f})')
    
    axes[0].set_xlabel('Prediction Error')
    axes[0].set_ylabel('Density')
    axes[0].set_title('Error Distribution with Normal Fit')
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)
    
    # 2. Q-Q å›¾æ£€éªŒæ­£æ€æ€§
    stats.probplot(errors, dist="norm", plot=axes[1])
    axes[1].set_title('Q-Q Plot for Normality Check')
    axes[1].grid(True, alpha=0.3)
    
    # 3. è¯¯å·®çš„è‡ªç›¸å…³åˆ†æï¼ˆå¦‚æœæ˜¯æ—¶é—´åºåˆ—ï¼‰
    if predictions.ndim >= 2:
        # é€‰æ‹©ä¸€ä¸ªæ ·æœ¬è¿›è¡Œè‡ªç›¸å…³åˆ†æ
        sample_errors = (predictions[0] - targets[0]).flatten() if predictions.ndim == 3 else predictions[0] - targets[0]
        if len(sample_errors) > 1:
            lags = range(1, min(20, len(sample_errors)))
            autocorrs = [np.corrcoef(sample_errors[:-lag], sample_errors[lag:])[0, 1] for lag in lags]
            
            axes[2].plot(lags, autocorrs, 'o-', linewidth=2)
            axes[2].axhline(y=0, color='r', linestyle='--', alpha=0.7)
            axes[2].set_xlabel('Lag')
            axes[2].set_ylabel('Autocorrelation')
            axes[2].set_title('Error Autocorrelation (Sample 1)')
            axes[2].grid(True, alpha=0.3)
    
    # 4. è¯¯å·®ç»Ÿè®¡æ‘˜è¦
    error_stats = {
        'Mean': np.mean(errors),
        'Std': np.std(errors),
        'Min': np.min(errors),
        'Max': np.max(errors),
        'Skewness': stats.skew(errors),
        'Kurtosis': stats.kurtosis(errors)
    }
    
    axes[3].axis('off')
    y_pos = 0.9
    axes[3].text(0.1, y_pos, 'Error Statistics:', fontsize=16, fontweight='bold', transform=axes[3].transAxes)
    for i, (stat, value) in enumerate(error_stats.items()):
        y_pos -= 0.12
        axes[3].text(0.1, y_pos, f'{stat}: {value:.6f}', fontsize=12, transform=axes[3].transAxes)
    
    plt.suptitle('Detailed Error Analysis', fontsize=16)
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'error_analysis.png'), dpi=300, bbox_inches='tight')
    plt.close()

def create_distribution_comparison(predictions, targets, output_dir):
    """åˆ›å»ºé¢„æµ‹å€¼å’ŒçœŸå®å€¼çš„åˆ†å¸ƒå¯¹æ¯”"""
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    axes = axes.flatten()
    
    pred_flat = predictions.flatten()
    true_flat = targets.flatten()
    
    # 1. ç›´æ–¹å›¾å¯¹æ¯”
    axes[0].hist(true_flat, bins=50, alpha=0.7, label='True Values', color='blue', density=True)
    axes[0].hist(pred_flat, bins=50, alpha=0.7, label='Predictions', color='red', density=True)
    axes[0].set_xlabel('Value')
    axes[0].set_ylabel('Density')
    axes[0].set_title('Distribution Comparison')
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)
    
    # 2. ç®±çº¿å›¾å¯¹æ¯”
    data_to_plot = [true_flat, pred_flat]
    axes[1].boxplot(data_to_plot, labels=['True Values', 'Predictions'])
    axes[1].set_ylabel('Value')
    axes[1].set_title('Box Plot Comparison')
    axes[1].grid(True, alpha=0.3)
    
    # 3. å°æç´å›¾å¯¹æ¯”
    parts = axes[2].violinplot([true_flat, pred_flat], positions=[1, 2])
    for pc, color in zip(parts['bodies'], ['blue', 'red']):
        pc.set_facecolor(color)
        pc.set_alpha(0.7)
    axes[2].set_xticks([1, 2])
    axes[2].set_xticklabels(['True Values', 'Predictions'])
    axes[2].set_ylabel('Value')
    axes[2].set_title('Violin Plot Comparison')
    axes[2].grid(True, alpha=0.3)
    
    # 4. ç´¯ç§¯åˆ†å¸ƒå‡½æ•°å¯¹æ¯”
    true_sorted = np.sort(true_flat)
    pred_sorted = np.sort(pred_flat)
    true_cdf = np.arange(1, len(true_sorted) + 1) / len(true_sorted)
    pred_cdf = np.arange(1, len(pred_sorted) + 1) / len(pred_sorted)
    
    axes[3].plot(true_sorted, true_cdf, 'b-', linewidth=2, label='True Values')
    axes[3].plot(pred_sorted, pred_cdf, 'r--', linewidth=2, label='Predictions')
    axes[3].set_xlabel('Value')
    axes[3].set_ylabel('Cumulative Probability')
    axes[3].set_title('Cumulative Distribution Comparison')
    axes[3].legend()
    axes[3].grid(True, alpha=0.3)
    
    # 5. åˆ†å¸ƒç»Ÿè®¡å¯¹æ¯”
    true_stats = {
        'Mean': np.mean(true_flat),
        'Std': np.std(true_flat),
        'Median': np.median(true_flat),
        'Skewness': stats.skew(true_flat),
        'Kurtosis': stats.kurtosis(true_flat)
    }
    
    pred_stats = {
        'Mean': np.mean(pred_flat),
        'Std': np.std(pred_flat),
        'Median': np.median(pred_flat),
        'Skewness': stats.skew(pred_flat),
        'Kurtosis': stats.kurtosis(pred_flat)
    }
    
    axes[4].axis('off')
    axes[4].text(0.05, 0.95, 'Distribution Statistics', fontsize=14, fontweight='bold', transform=axes[4].transAxes)
    axes[4].text(0.05, 0.85, 'True Values:', fontsize=12, fontweight='bold', color='blue', transform=axes[4].transAxes)
    axes[4].text(0.55, 0.85, 'Predictions:', fontsize=12, fontweight='bold', color='red', transform=axes[4].transAxes)
    
    y_pos = 0.75
    for stat in true_stats.keys():
        axes[4].text(0.05, y_pos, f'{stat}: {true_stats[stat]:.4f}', fontsize=10, transform=axes[4].transAxes)
        axes[4].text(0.55, y_pos, f'{stat}: {pred_stats[stat]:.4f}', fontsize=10, transform=axes[4].transAxes)
        y_pos -= 0.08
    
    # 6. åˆ†ä½æ•°-åˆ†ä½æ•°å›¾
    n_quantiles = 100
    quantiles = np.linspace(0, 100, n_quantiles)
    true_quantiles = np.percentile(true_flat, quantiles)
    pred_quantiles = np.percentile(pred_flat, quantiles)
    
    axes[5].scatter(true_quantiles, pred_quantiles, alpha=0.6)
    min_val = min(true_quantiles.min(), pred_quantiles.min())
    max_val = max(true_quantiles.max(), pred_quantiles.max())
    axes[5].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect Match')
    axes[5].set_xlabel('True Value Quantiles')
    axes[5].set_ylabel('Predicted Value Quantiles')
    axes[5].set_title('Quantile-Quantile Plot')
    axes[5].legend()
    axes[5].grid(True, alpha=0.3)
    
    plt.suptitle('Distribution Comparison Analysis', fontsize=16)
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'distribution_comparison.png'), dpi=300, bbox_inches='tight')
    plt.close()

def create_metrics_dashboard(metrics, output_dir):
    """åˆ›å»ºæ€§èƒ½æŒ‡æ ‡ä»ªè¡¨æ¿"""
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    axes = axes.flatten()
    
    metric_names = list(metrics.keys())
    metric_values = list(metrics.values())
    
    # é¢œè‰²æ˜ å°„
    colors = plt.cm.Set3(np.linspace(0, 1, len(metric_names)))
    
    # ä¸ºæ¯ä¸ªæŒ‡æ ‡åˆ›å»ºæŸ±çŠ¶å›¾
    for i, (name, value) in enumerate(zip(metric_names, metric_values)):
        if i < len(axes):
            ax = axes[i]
            bar = ax.bar([name], [value], alpha=0.8, color=colors[i], 
                        edgecolor='black', linewidth=2)
            ax.text(0, value/2, f'{value:.4f}', ha='center', va='center', 
                   fontsize=14, fontweight='bold')
            ax.set_title(f'{name}', fontsize=14, fontweight='bold')
            ax.set_ylabel('Value')
            ax.grid(True, alpha=0.3, axis='y')
            
            # ä¸ºæŸäº›æŒ‡æ ‡æ·»åŠ å‚è€ƒçº¿
            if name == 'Correlation':
                ax.axhline(y=1.0, color='green', linestyle='--', alpha=0.7, label='Perfect')
                ax.axhline(y=0.9, color='orange', linestyle='--', alpha=0.7, label='Excellent')
                ax.axhline(y=0.7, color='red', linestyle='--', alpha=0.7, label='Good')
                ax.legend()
            elif name == 'R2_Score':
                ax.axhline(y=1.0, color='green', linestyle='--', alpha=0.7, label='Perfect')
                ax.axhline(y=0.8, color='orange', linestyle='--', alpha=0.7, label='Good')
                ax.legend()
    
    # éšè—å¤šä½™çš„å­å›¾
    for i in range(len(metric_names), len(axes)):
        axes[i].set_visible(False)
    
    plt.suptitle('Performance Metrics Dashboard', fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'metrics_dashboard.png'), dpi=300, bbox_inches='tight')
    plt.close()

def create_multidimensional_analysis(predictions, targets, output_dir):
    """åˆ›å»ºå¤šç»´æ•°æ®åˆ†æ"""
    if predictions.ndim != 3:
        return
    
    n_samples, n_features, seq_len = predictions.shape
    
    fig = plt.figure(figsize=(20, 15))
    gs = fig.add_gridspec(3, 4, hspace=0.3, wspace=0.3)
    
    # 1. ç‰¹å¾ç»´åº¦çš„å¹³å‡è¯¯å·®
    feature_errors = np.mean(np.abs(predictions - targets), axis=(0, 2))
    
    ax1 = fig.add_subplot(gs[0, 0])
    bars = ax1.bar(range(n_features), feature_errors, alpha=0.8)
    ax1.set_xlabel('Feature Index')
    ax1.set_ylabel('Mean Absolute Error')
    ax1.set_title('Error by Feature Dimension')
    ax1.grid(True, alpha=0.3)
    
    # 2. æ—¶é—´æ­¥çš„å¹³å‡è¯¯å·®
    timestep_errors = np.mean(np.abs(predictions - targets), axis=(0, 1))
    
    ax2 = fig.add_subplot(gs[0, 1])
    ax2.plot(range(seq_len), timestep_errors, 'o-', linewidth=2, markersize=4)
    ax2.set_xlabel('Time Step')
    ax2.set_ylabel('Mean Absolute Error')
    ax2.set_title('Error by Time Step')
    ax2.grid(True, alpha=0.3)
    
    # 3. ç‰¹å¾ç»´åº¦çƒ­åŠ›å›¾ï¼ˆå‰10ä¸ªæ ·æœ¬ï¼‰
    ax3 = fig.add_subplot(gs[0, 2])
    sample_errors = np.abs(predictions[:10] - targets[:10])  # å‰10ä¸ªæ ·æœ¬
    avg_sample_errors = np.mean(sample_errors, axis=2)  # å¯¹æ—¶é—´ç»´åº¦æ±‚å¹³å‡
    
    im = ax3.imshow(avg_sample_errors.T, cmap='viridis', aspect='auto')
    ax3.set_xlabel('Sample Index')
    ax3.set_ylabel('Feature Index')
    ax3.set_title('Error Heatmap (Samples vs Features)')
    plt.colorbar(im, ax=ax3)
    
    # 4. æ—¶é—´-ç‰¹å¾è¯¯å·®çƒ­åŠ›å›¾
    ax4 = fig.add_subplot(gs[0, 3])
    avg_errors_time_feature = np.mean(np.abs(predictions - targets), axis=0)
    
    im = ax4.imshow(avg_errors_time_feature, cmap='viridis', aspect='auto')
    ax4.set_xlabel('Time Step')
    ax4.set_ylabel('Feature Index')
    ax4.set_title('Error Heatmap (Features vs Time)')
    plt.colorbar(im, ax=ax4)
    
    # 5. æ ·æœ¬é—´è¯¯å·®åˆ†å¸ƒ
    ax5 = fig.add_subplot(gs[1, :2])
    sample_total_errors = np.mean(np.abs(predictions - targets), axis=(1, 2))
    
    ax5.hist(sample_total_errors, bins=30, alpha=0.7, edgecolor='black')
    ax5.axvline(np.mean(sample_total_errors), color='red', linestyle='--', 
               label=f'Mean: {np.mean(sample_total_errors):.4f}')
    ax5.set_xlabel('Mean Absolute Error')
    ax5.set_ylabel('Number of Samples')
    ax5.set_title('Distribution of Sample Errors')
    ax5.legend()
    ax5.grid(True, alpha=0.3)
    
    # 6. ç‰¹å¾é‡è¦æ€§ï¼ˆåŸºäºé¢„æµ‹è¯¯å·®ï¼‰
    ax6 = fig.add_subplot(gs[1, 2:])
    feature_importance = 1 / (feature_errors + 1e-8)  # è¯¯å·®è¶Šå°ï¼Œé‡è¦æ€§è¶Šé«˜
    feature_importance = feature_importance / np.sum(feature_importance)  # å½’ä¸€åŒ–
    
    bars = ax6.bar(range(n_features), feature_importance, alpha=0.8)
    ax6.set_xlabel('Feature Index')
    ax6.set_ylabel('Relative Importance')
    ax6.set_title('Feature Importance (Based on Prediction Error)')
    ax6.grid(True, alpha=0.3)
    
    # 7. ç›¸å…³æ€§çŸ©é˜µï¼ˆç‰¹å¾é—´çš„é¢„æµ‹ç›¸å…³æ€§ï¼‰
    ax7 = fig.add_subplot(gs[2, :2])
    pred_features_flat = predictions.reshape(-1, n_features)
    true_features_flat = targets.reshape(-1, n_features)
    
    corr_matrix = np.corrcoef(pred_features_flat.T, true_features_flat.T)[:n_features, n_features:]
    
    im = ax7.imshow(corr_matrix, cmap='coolwarm', vmin=-1, vmax=1)
    ax7.set_xlabel('True Feature Index')
    ax7.set_ylabel('Predicted Feature Index')
    ax7.set_title('Cross-Correlation Matrix (Pred vs True)')
    plt.colorbar(im, ax=ax7)
    
    # 8. æ—¶åºé¢„æµ‹è´¨é‡åˆ†æ
    ax8 = fig.add_subplot(gs[2, 2:])
    # è®¡ç®—æ¯ä¸ªæ—¶é—´æ­¥çš„å¹³å‡ç›¸å…³æ€§
    timestep_correlations = []
    for t in range(seq_len):
        pred_t = predictions[:, :, t].flatten()
        true_t = targets[:, :, t].flatten()
        if np.std(pred_t) > 1e-8 and np.std(true_t) > 1e-8:
            corr = np.corrcoef(pred_t, true_t)[0, 1]
            if not np.isnan(corr):
                timestep_correlations.append(corr)
            else:
                timestep_correlations.append(0)
        else:
            timestep_correlations.append(0)
    
    ax8.plot(range(len(timestep_correlations)), timestep_correlations, 'o-', linewidth=2)
    ax8.set_xlabel('Time Step')
    ax8.set_ylabel('Correlation')
    ax8.set_title('Prediction Quality over Time')
    ax8.grid(True, alpha=0.3)
    ax8.set_ylim([-1, 1])
    
    plt.suptitle('Multi-dimensional Data Analysis', fontsize=16)
    plt.savefig(os.path.join(output_dir, 'multidimensional_analysis.png'), dpi=300, bbox_inches='tight')
    plt.close()

def main():
    parser = argparse.ArgumentParser(description='Evaluate tfdiff model with enhanced visualizations')
    parser.add_argument('--task_id', type=int, default=4,
                       help='Task ID (0/1/2/3/4 for WiFi/FMCW/MIMO/EEG/Traffic)')
    parser.add_argument('--checkpoint', type=str, default=None,
                       help='Path to model checkpoint (default: auto-detect in model_dir)')
    parser.add_argument('--batch_size', type=int, default=16,
                       help='Batch size for evaluation')
    parser.add_argument('--device', type=str, default='cuda',
                       choices=['cuda', 'cpu'], help='Device to use')
    parser.add_argument('--num_samples', type=int, default=None,
                       help='Number of samples to evaluate (default: all)')
    parser.add_argument('--output_dir', type=str, default='./eval_results',
                       help='Directory to save evaluation results')
    parser.add_argument('--save_predictions', action='store_true',
                       help='Save predictions and targets to file')
    parser.add_argument('--no_visualization', action='store_true',
                       help='Skip creating visualizations')
    parser.add_argument('--pred_len', type=int, default=20,
                       help='Prediction length for task 4 (traffic prediction)')
    # ğŸ”§ æ–°å¢å‚æ•°
    parser.add_argument('--model_type', type=str, default=None,
                       choices=['ConditionalUNet', 'tfdiff_WiFi', 'MaskedDiffusion'],
                       help='Force specific model type (default: auto-detect)')
    parser.add_argument('--skip_nan_check', action='store_true',
                       help='Skip NaN checking in predictions')
    
    args = parser.parse_args()
    
    # è®¾ç½®éšæœºç§å­
    seed_everything(42)
    
    # è·å–è®¾å¤‡
    device = get_device(args.device)
    print(f"Using device: {device}")
    
    # æ„å»ºå‚æ•°
    params = build_params(args.task_id, device.type, args.pred_len)
    
    # é‡å†™æ‰¹æ¬¡å¤§å°
    params.batch_size = args.batch_size
    
    print(f"Evaluating task_id={args.task_id} with parameters:")
    print(f"  Model dir: {params.model_dir}")
    print(f"  Data dir: {params.data_dir}")
    print(f"  Batch size: {params.batch_size}")
    
    # ğŸ”§ å¯»æ‰¾checkpointæ–‡ä»¶
    if args.checkpoint is None:
        # å°è¯•å¤šä¸ªå¯èƒ½çš„æ£€æŸ¥ç‚¹æ–‡ä»¶å
        possible_checkpoints = [
            os.path.join(params.model_dir, 'best_model.pt'),
            os.path.join(params.model_dir, 'traffic_model_final.pt'),
            os.path.join(params.model_dir, 'checkpoint.pt'),
            os.path.join(params.model_dir, 'weights.pt'),
            os.path.join(params.model_dir, 'model.pt'),
            os.path.join(params.model_dir, 'best_masked_diffusion_model.pt'),  # ğŸ”§ æ–°å¢
        ]
        
        checkpoint_path = None
        for path in possible_checkpoints:
            if os.path.exists(path):
                checkpoint_path = path
                break
        
        if checkpoint_path is None:
            raise FileNotFoundError(f"No checkpoint found in {params.model_dir}. "
                                   f"Tried: {possible_checkpoints}")
    else:
        checkpoint_path = args.checkpoint
    
    print(f"ğŸ“ Using checkpoint: {checkpoint_path}")
    
    # ğŸ”§ æ£€æµ‹å¹¶åˆ›å»ºé€‚å½“çš„æ¨¡å‹
    model_type = args.model_type or detect_model_type(checkpoint_path)
    
    if model_type == 'MaskedDiffusion' and MASKED_DIFFUSION_AVAILABLE:
        # åˆ›å»ºä¿®å¤ç‰ˆæ‰©æ•£æ¨¡å‹
        from wifi_model import MaskedDiffusionConfig
        config = MaskedDiffusionConfig()
        config.device = device.type
        config.input_dim = params.input_dim
        config.cond_dim = getattr(params, 'cond_dim', 148)
        config.seq_len = getattr(params, 'seq_len', 10)
        config.pred_len = getattr(params, 'pred_len', 10)
        
        model = create_masked_diffusion_model(config)
        diffusion = None  # ä¿®å¤ç‰ˆæ¨¡å‹å†…ç½®äº†æ‰©æ•£è¿‡ç¨‹
        print("ğŸ—ï¸ Created MaskedDiffusion model")
        
    elif model_type == 'ConditionalUNet':
        from model import ConditionalUNet
        model = ConditionalUNet(params).to(device)
        diffusion = create_diffusion(params, device)
        print("ğŸ—ï¸ Created ConditionalUNet model")
        
    else:
        model = tfdiff_WiFi(params).to(device)
        diffusion = create_diffusion(params, device)
        print("ğŸ—ï¸ Created tfdiff_WiFi model")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨ï¼ˆè¯„ä¼°æ¨¡å¼ï¼‰
    print("Loading dataset...")
    dataset = from_path(params)
    
    # éªŒè¯æ•°æ®é›†
    try:
        first_batch = next(iter(dataset))
        print(f"âœ… Dataset loaded successfully")
        if isinstance(first_batch, dict):
            print(f"  Batch keys: {list(first_batch.keys())}")
            for key, value in first_batch.items():
                if torch.is_tensor(value):
                    print(f"  {key}: {value.shape}")
        else:
            print(f"  Batch shape: {first_batch.shape}")
    except Exception as e:
        raise ValueError(f"Error loading dataset: {e}")
    
    # åŠ è½½æ£€æŸ¥ç‚¹
    load_model_checkpoint(model, checkpoint_path, device)
    
    # è¯„ä¼°æ¨¡å‹
    print("Starting model evaluation...")
    metrics, predictions, targets = evaluate_model(
        model, diffusion, dataset, device, params, args.num_samples
    )
    
    # ğŸ”§ æ£€æŸ¥ç»“æœçš„æœ‰æ•ˆæ€§
    if not args.skip_nan_check:
        pred_nan_count = np.isnan(predictions.cpu().numpy()).sum() if torch.is_tensor(predictions) else np.isnan(predictions).sum()
        target_nan_count = np.isnan(targets.cpu().numpy()).sum() if torch.is_tensor(targets) else np.isnan(targets).sum()
        
        if pred_nan_count > 0:
            print(f"âš ï¸ Found {pred_nan_count} NaN values in predictions")
        if target_nan_count > 0:
            print(f"âš ï¸ Found {target_nan_count} NaN values in targets")
    
    # æ‰“å°ç»“æœ
    print("\n" + "="*60)
    print("ğŸ“Š EVALUATION RESULTS")
    print("="*60)
    for metric_name, metric_value in metrics.items():
        print(f"  {metric_name:15}: {metric_value:.6f}")
    print("="*60)
    
    # åˆ›å»ºå¢å¼ºçš„å¯è§†åŒ–
    if not args.no_visualization:
        print("\nğŸ¨ Creating comprehensive visualizations...")
        create_comprehensive_visualizations(predictions, targets, metrics, args.output_dir, args.task_id)
        print("âœ… All visualizations completed!")
    
    # ä¿å­˜ç»“æœ
    os.makedirs(args.output_dir, exist_ok=True)
    
    metrics_path = os.path.join(args.output_dir, f'metrics_task{args.task_id}.json')
    with open(metrics_path, 'w') as f:
        json.dump(metrics, f, indent=2)
    print(f"ğŸ“ Metrics saved to: {metrics_path}")
    
    # ä¿å­˜é¢„æµ‹ç»“æœï¼ˆå¦‚æœrequestedï¼‰
    if args.save_predictions:
        predictions_path = os.path.join(args.output_dir, f'predictions_task{args.task_id}.npz')
        np.savez(predictions_path, 
                predictions=predictions.cpu().numpy() if torch.is_tensor(predictions) else predictions, 
                targets=targets.cpu().numpy() if torch.is_tensor(targets) else targets)
        print(f"ğŸ’¾ Predictions saved to: {predictions_path}")
    
    print("\nğŸ‰ Evaluation completed successfully!")
    print(f"ğŸ“ All results saved to: {args.output_dir}")

if __name__ == '__main__':
    main()
